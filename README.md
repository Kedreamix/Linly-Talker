# Digital Avatar Conversational System - Linly-Talker

[English](./README.md) [ç®€ä½“ä¸­æ–‡](./README_zh.md)

**2023.12 Update** ðŸ“†

**Users can upload any images for the conversation**



## Introduction

Linly-Talker is an intelligent AI system that combines large language models (LLMs) with visual models to create a novel human-AI interaction method. It integrates various technologies like Whisper, Linly, Microsoft Speech Services and SadTalker talking head generation system. The system is deployed on Gradio to allow users to converse with an AI assistant by providing images as prompts. Users can have free-form conversations or generate content according to their preferences.

![The system architecture of multimodal humanâ€“computer interaction.](HOI.png)

## Setup

```
conda create -n linly python=3.8
conda activate linly

pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113 

conda install ffmpeg

pip install -r requirements_app.txt
```

## ASR - Whisper

Leverages OpenAI's Whisper, see [https://github.com/openai/whisper](https://github.com/openai/whisper) for usage.

## TTS - Edge TTS

Uses Microsoft Speech Services, see [https://github.com/rany2/edge-tts](https://github.com/rany2/edge-tts) for usage. 

## THG - SadTalker

Talking head generation uses SadTalker from CVPR 2023, see [https://sadtalker.github.io](https://sadtalker.github.io)

Download SadTalker models:

```
bash scripts/download_models.sh
```

## LLM - Linly 

Linly from CVI , Shenzhen University, see https://github.com/CVI-SZU/Linly

Download Linly models: https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf

```
git lfs install
git clone https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf
```

Or use the API:

```
# CLI
curl -X POST -H "Content-Type: application/json" -d '{"question": "What are fun places in Beijing?"}' http://url:port

# Python
import requests

url = "http://url:port"  
headers = {
  "Content-Type": "application/json" 
}

data = {
  "question": "What are fun places in Beijing?"
}

response = requests.post(url, headers=headers, json=data)
# response_text = response.content.decode("utf-8")
answer, tag = response.json()
# print(answer)
if tag == 'success':
    response_text =  answer[0]
else:
    print("fail")
print(response_text)
```

## Optimizations

Some optimizations:

- Use fixed input face images, extract features beforehand to avoid reading each time
- Remove unnecessary libraries to reduce total time
- Only save final video output, don't save intermediate results to improve performance 
- Use OpenCV to generate final video instead of mimwrite for faster runtime

## Gradio

Gradio is a Python library that provides an easy way to deploy machine learning models as interactive web apps. 

For Linly-Talker, Gradio serves two main purposes:

1. **Visualization & Demo**: Gradio provides a simple web GUI for the model, allowing users to see the results intuitively by uploading an image and entering text. This is an effective way to showcase the capabilities of the system.

2. **User Interaction**: The Gradio GUI can serve as a frontend to allow end users to interact with Linly-Talker. Users can upload their own images and ask arbitrary questions or have conversations to get real-time responses. This provides a more natural speech interaction method.

Specifically, we create a Gradio Interface in app.py that takes image and text inputs, calls our function to generate the response video, and displays it in the GUI. This enables browser interaction without needing to build complex frontend. 

In summary, Gradio provides visualization and user interaction interfaces for Linly-Talker, serving as effective means for showcasing system capabilities and enabling end users.

## Usage

The folder structure is as follows:

```bash
Linly-Talker/
â”œâ”€â”€ app.py
â”œâ”€â”€ app_img.py 
â”œâ”€â”€ utils.py
â”œâ”€â”€ Linly-api.py
â”œâ”€â”€ Linly-example.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ README_zh.md
â”œâ”€â”€ request-Linly-api.py
â”œâ”€â”€ requirements_app.txt
â”œâ”€â”€ scripts
   â””â”€â”€ download_models.sh
â”œâ”€â”€ src
   â””â”€â”€ .....
â”œâ”€â”€ inputs
   â”œâ”€â”€ example.png
   â””â”€â”€ first_frame_dir
       â”œâ”€â”€ example_landmarks.txt
       â”œâ”€â”€ example.mat
       â””â”€â”€ example.png
â”œâ”€â”€ examples
   â”œâ”€â”€ driven_audio
      â”œâ”€â”€ bus_chinese.wav
      â”œâ”€â”€ ......
      â””â”€â”€ RD_Radio40_000.wav
   â”œâ”€â”€ ref_video
      â”œâ”€â”€ WDA_AlexandriaOcasioCortez_000.mp4
      â””â”€â”€ WDA_KatieHill_000.mp4
   â””â”€â”€ source_image
       â”œâ”€â”€ art_0.png
       â”œâ”€â”€ ......
       â””â”€â”€ sad.png
â”œâ”€â”€ checkpoints // SadTalker model weights path
   â”œâ”€â”€ mapping_00109-model.pth.tar
   â”œâ”€â”€ mapping_00229-model.pth.tar
   â”œâ”€â”€ SadTalker_V0.0.2_256.safetensors
   â””â”€â”€ SadTalker_V0.0.2_512.safetensors
â”œâ”€â”€ gfpgan // GFPGAN model weights path
   â””â”€â”€ weights
       â”œâ”€â”€ alignment_WFLW_4HG.pth
       â””â”€â”€ detection_Resnet50_Final.pth
â”œâ”€â”€ Chinese-LLaMA-2-7B-hf // Linly model weights path
    â”œâ”€â”€ config.json
    â”œâ”€â”€ generation_config.json
    â”œâ”€â”€ pytorch_model-00001-of-00002.bin
    â”œâ”€â”€ pytorch_model-00002-of-00002.bin
    â”œâ”€â”€ pytorch_model.bin.index.json
    â”œâ”€â”€ README.md
    â”œâ”€â”€ special_tokens_map.json
    â”œâ”€â”€ tokenizer_config.json
    â””â”€â”€ tokenizer.model
```

Next, launch the app:

```
python app.py
```

![](UI.jpg)

Users can upload images for the conversation

```bash
python app_img.py
```

![](UI2.jpg)

## Reference

- [https://github.com/openai/whisper](https://github.com/openai/whisper)
- [https://github.com/rany2/edge-tts](https://github.com/rany2/edge-tts)  
- [https://github.com/CVI-SZU/Linly](https://github.com/CVI-SZU/Linly)
- [https://github.com/OpenTalker/SadTalker](https://github.com/OpenTalker/SadTalker)


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Kedreamix/Linly-Talker&type=Date)](https://star-history.com/#Kedreamix/Linly-Talker&Date)

