# æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€

<div align="center">
<h1>Linly-Talker WebUI</h1>

[![madewithlove](https://img.shields.io/badge/made_with-%E2%9D%A4-red?style=for-the-badge&labelColor=orange)](https://github.com/Kedreamix/Linly-Talker)

<img src="https://github.com/CVI-SZU/Linly/raw/main/assets/linly_logo.png" /><br>

[![Open In Colab](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252)](https://colab.research.google.com/github/Kedreamix/Linly-Talker/blob/main/colab_webui.ipynb)
[![Licence](https://img.shields.io/badge/LICENSE-MIT-green.svg?style=for-the-badge)](https://github.com/Kedreamix/Linly-Talker/blob/main/LICENSE)
[![Huggingface](https://img.shields.io/badge/ğŸ¤—%20-Models%20Repo-yellow.svg?style=for-the-badge)](https://huggingface.co/Kedreamix/Linly-Talker)

[**English**](./README_en.md) | [**ä¸­æ–‡ç®€ä½“**](./README.md)

</div>

**2023.12 æ›´æ–°** ğŸ“†

**ç”¨æˆ·å¯ä»¥ä¸Šä¼ ä»»æ„å›¾ç‰‡è¿›è¡Œå¯¹è¯**

**2024.01 æ›´æ–°** ğŸ“†

- **ä»¤äººå…´å¥‹çš„æ¶ˆæ¯ï¼æˆ‘ç°åœ¨å·²ç»å°†å¼ºå¤§çš„GeminiProå’ŒQwenå¤§æ¨¡å‹èå…¥åˆ°æˆ‘ä»¬çš„å¯¹è¯åœºæ™¯ä¸­ã€‚ç”¨æˆ·ç°åœ¨å¯ä»¥åœ¨å¯¹è¯ä¸­ä¸Šä¼ ä»»ä½•å›¾ç‰‡ï¼Œä¸ºæˆ‘ä»¬çš„äº’åŠ¨å¢æ·»äº†å…¨æ–°çš„å±‚é¢ã€‚**
- **æ›´æ–°äº†FastAPIçš„éƒ¨ç½²è°ƒç”¨æ–¹æ³•ã€‚** 
- **æ›´æ–°äº†å¾®è½¯TTSçš„é«˜çº§è®¾ç½®é€‰é¡¹ï¼Œå¢åŠ å£°éŸ³ç§ç±»çš„å¤šæ ·æ€§ï¼Œä»¥åŠåŠ å…¥è§†é¢‘å­—å¹•åŠ å¼ºå¯è§†åŒ–ã€‚**
  - **æ›´æ–°äº†GPTå¤šè½®å¯¹è¯ç³»ç»Ÿï¼Œä½¿å¾—å¯¹è¯æœ‰ä¸Šä¸‹æ–‡è”ç³»ï¼Œæé«˜æ•°å­—äººçš„äº¤äº’æ€§å’ŒçœŸå®æ„Ÿã€‚**


**2024.02 æ›´æ–°** ğŸ“†

- **æ›´æ–°äº†Gradioçš„ç‰ˆæœ¬ä¸ºæœ€æ–°ç‰ˆæœ¬4.16.0ï¼Œä½¿å¾—ç•Œé¢æ‹¥æœ‰æ›´å¤šçš„åŠŸèƒ½ï¼Œæ¯”å¦‚å¯ä»¥æ‘„åƒå¤´æ‹æ‘„å›¾ç‰‡æ„å»ºæ•°å­—äººç­‰ã€‚**
- **æ›´æ–°äº†ASRå’ŒTHGï¼Œå…¶ä¸­ASRåŠ å…¥äº†é˜¿é‡Œçš„FunASRï¼Œå…·ä½“æ›´å¿«çš„é€Ÿåº¦ï¼›THGéƒ¨åˆ†åŠ å…¥äº†Wav2Lipæ¨¡å‹ï¼ŒER-NeRFåœ¨å‡†å¤‡ä¸­(Comming Soon)ã€‚**
- **åŠ å…¥äº†è¯­éŸ³å…‹éš†æ–¹æ³•GPT-SoVITSæ¨¡å‹ï¼Œèƒ½å¤Ÿé€šè¿‡å¾®è°ƒä¸€åˆ†é’Ÿå¯¹åº”äººçš„è¯­æ–™è¿›è¡Œå…‹éš†ï¼Œæ•ˆæœè¿˜æ˜¯ç›¸å½“ä¸é”™çš„ï¼Œå€¼å¾—æ¨èã€‚**
- **é›†æˆä¸€ä¸ªWebUIç•Œé¢ï¼Œèƒ½å¤Ÿæ›´å¥½çš„è¿è¡ŒLinly-Talkerã€‚**

---



## ä»‹ç»

Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚

![The system architecture of multimodal humanâ€“computer interaction.](docs/HOI.png)

> æŸ¥çœ‹æˆ‘ä»¬çš„ä»‹ç»è§†é¢‘ [demo video](https://www.bilibili.com/video/BV1rN4y1a76x/)

## TO DO LIST

- [x] åŸºæœ¬å®Œæˆå¯¹è¯ç³»ç»Ÿæµç¨‹ï¼Œèƒ½å¤Ÿ`è¯­éŸ³å¯¹è¯`
- [x] åŠ å…¥äº†LLMå¤§æ¨¡å‹ï¼ŒåŒ…æ‹¬`Linly`ï¼Œ`Qwen`å’Œ`GeminiPro`çš„ä½¿ç”¨
- [x] å¯ä¸Šä¼ `ä»»æ„æ•°å­—äººç…§ç‰‡`è¿›è¡Œå¯¹è¯
- [x] LinlyåŠ å…¥`FastAPI`è°ƒç”¨æ–¹å¼
- [x] åˆ©ç”¨å¾®è½¯`TTS`åŠ å…¥é«˜çº§é€‰é¡¹ï¼Œå¯è®¾ç½®å¯¹åº”äººå£°ä»¥åŠéŸ³è°ƒç­‰å‚æ•°ï¼Œå¢åŠ å£°éŸ³çš„å¤šæ ·æ€§
- [x] è§†é¢‘ç”ŸæˆåŠ å…¥`å­—å¹•`ï¼Œèƒ½å¤Ÿæ›´å¥½çš„è¿›è¡Œå¯è§†åŒ–
- [x] GPT`å¤šè½®å¯¹è¯`ç³»ç»Ÿï¼ˆæé«˜æ•°å­—äººçš„äº¤äº’æ€§å’ŒçœŸå®æ„Ÿï¼Œå¢å¼ºæ•°å­—äººçš„æ™ºèƒ½ï¼‰
- [x] ä¼˜åŒ–Gradioç•Œé¢ï¼ŒåŠ å…¥æ›´å¤šæ¨¡å‹ï¼Œå¦‚Wav2Lipï¼ŒFunASRç­‰
- [x] `è¯­éŸ³å…‹éš†`æŠ€æœ¯ï¼ŒåŠ å…¥GPT-SoVITSï¼Œåªéœ€è¦ä¸€åˆ†é’Ÿçš„è¯­éŸ³ç®€å•å¾®è°ƒå³å¯ï¼ˆè¯­éŸ³å…‹éš†åˆæˆè‡ªå·±å£°éŸ³ï¼Œæé«˜æ•°å­—äººåˆ†èº«çš„çœŸå®æ„Ÿå’Œäº’åŠ¨ä½“éªŒï¼‰
- [ ] åŠ å…¥`Langchain`çš„æ¡†æ¶ï¼Œå»ºç«‹æœ¬åœ°çŸ¥è¯†åº“
- [ ] `å®æ—¶`è¯­éŸ³è¯†åˆ«ï¼ˆäººä¸æ•°å­—äººä¹‹é—´å°±å¯ä»¥é€šè¿‡è¯­éŸ³è¿›è¡Œå¯¹è¯äº¤æµ)

ğŸ”† è¯¥é¡¹ç›® Linly-Talker æ­£åœ¨è¿›è¡Œä¸­ - æ¬¢è¿æå‡ºPRè¯·æ±‚ï¼å¦‚æœæ‚¨æœ‰ä»»ä½•å…³äºæ–°çš„æ¨¡å‹æ–¹æ³•ã€ç ”ç©¶ã€æŠ€æœ¯æˆ–å‘ç°è¿è¡Œé”™è¯¯çš„å»ºè®®ï¼Œè¯·éšæ—¶ç¼–è¾‘å¹¶æäº¤ PRã€‚æ‚¨ä¹Ÿå¯ä»¥æ‰“å¼€ä¸€ä¸ªé—®é¢˜æˆ–é€šè¿‡ç”µå­é‚®ä»¶ç›´æ¥è”ç³»æˆ‘ã€‚ğŸ“©â­ å¦‚æœæ‚¨å‘ç°è¿™ä¸ªGithub Projectæœ‰ç”¨ï¼Œè¯·ç»™å®ƒç‚¹ä¸ªæ˜Ÿï¼ğŸ¤©

## ç¤ºä¾‹

|                        æ–‡å­—/è¯­éŸ³å¯¹è¯                         |                          æ•°å­—äººå›ç­”                          |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
|                 åº”å¯¹å‹åŠ›æœ€æœ‰æ•ˆçš„æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ                 | <video src="https://github.com/Kedreamix/Linly-Talker/assets/61195303/f1deb189-b682-4175-9dea-7eeb0fb392ca"></video> |
|                      å¦‚ä½•è¿›è¡Œæ—¶é—´ç®¡ç†ï¼Ÿ                      | <video src="https://github.com/Kedreamix/Linly-Talker/assets/61195303/968b5c43-4dce-484b-b6c6-0fd4d621ac03"></video> |
|  æ’°å†™ä¸€ç¯‡äº¤å“ä¹éŸ³ä¹ä¼šè¯„è®ºï¼Œè®¨è®ºä¹å›¢çš„è¡¨æ¼”å’Œè§‚ä¼—çš„æ•´ä½“ä½“éªŒã€‚  | <video src="https://github.com/Kedreamix/Linly-Talker/assets/61195303/f052820f-6511-4cf0-a383-daf8402630db"></video> |
| ç¿»è¯‘æˆä¸­æ–‡ï¼šLuck is a dividend of sweat. The more you sweat, the luckier you get. | <video src="https://github.com/Kedreamix/Linly-Talker/assets/61195303/118eec13-a9f7-4c38-b4ad-044d36ba9776"></video> |

## åˆ›å»ºç¯å¢ƒ

```bash
conda create -n linly python=3.10  
conda activate linly

# pytorchå®‰è£…æ–¹å¼1ï¼šcondaå®‰è£…ï¼ˆæ¨èï¼‰
conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch

# pytorchå®‰è£…æ–¹å¼2ï¼špip å®‰è£…
pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113

conda install -q ffmpeg # ffmpeg==4.2.2

pip install -r requirements_app.txt
```

è‹¥ä½¿ç”¨è¯­éŸ³å…‹éš†ç­‰æ¨¡å‹ï¼Œéœ€è¦æ›´é«˜ç‰ˆæœ¬çš„Pytorchï¼Œä½†æ˜¯åŠŸèƒ½ä¹Ÿä¼šæ›´åŠ ä¸°å¯Œï¼Œä¸è¿‡éœ€è¦çš„é©±åŠ¨ç‰ˆæœ¬å¯èƒ½è¦åˆ°cuda11.8ï¼Œå¯é€‰æ‹©

```bash
conda create -n linly python=3.10  
conda activate linly

pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118

conda install -q ffmpeg # ffmpeg==4.2.2

pip install -r requirements_app.txt

# å®‰è£…è¯­éŸ³å…‹éš†å¯¹åº”çš„ä¾èµ–
pip install -r VITS/requirements_gptsovits.txt
```

ä¸ºäº†å¤§å®¶çš„éƒ¨ç½²ä½¿ç”¨æ–¹ä¾¿ï¼Œæ›´æ–°äº†ä¸€ä¸ª`configs.py`æ–‡ä»¶ï¼Œå¯ä»¥å¯¹å…¶è¿›è¡Œä¸€äº›è¶…å‚æ•°ä¿®æ”¹å³å¯

```bash
# è®¾å¤‡è¿è¡Œç«¯å£ (Device running port)
port = 7860
# apiè¿è¡Œç«¯å£åŠIP (API running port and IP)
mode = 'api' # api éœ€è¦å…ˆè¿è¡ŒLinly-api-fast.pyï¼Œæš‚æ—¶ä»…ä»…é€‚ç”¨äºLinly
ip = '127.0.0.1' 
api_port = 7871

# Læ¨¡å‹è·¯å¾„ (Linly model path)
mode = 'offline'
model_path = 'Qwen/Qwen-1_8B-Chat'

# sslè¯ä¹¦ (SSL certificate) éº¦å…‹é£å¯¹è¯éœ€è¦æ­¤å‚æ•°
# æœ€å¥½è°ƒæ•´ä¸ºç»å¯¹è·¯å¾„
ssl_certfile = "./https_cert/cert.pem"
ssl_keyfile = "./https_cert/key.pem"
```

## ASR - Speech Recognition

### Whisper

å€Ÿé‰´OpenAIçš„Whisperå®ç°äº†ASRçš„è¯­éŸ³è¯†åˆ«ï¼Œå…·ä½“ä½¿ç”¨æ–¹æ³•å‚è€ƒ [https://github.com/openai/whisper](https://github.com/openai/whisper)

```python
'''
https://github.com/openai/whisper
pip install -U openai-whisper
'''
import whisper

class WhisperASR:
    def __init__(self, model_path):
        self.LANGUAGES = {
            "en": "english",
            "zh": "chinese",
        }
        self.model = whisper.load_model(model_path)
        
    def transcribe(self, audio_file):
        result = self.model.transcribe(audio_file)
        return result["text"]
```



### FunASR

é˜¿é‡Œçš„`FunASR`çš„è¯­éŸ³è¯†åˆ«æ•ˆæœä¹Ÿæ˜¯ç›¸å½“ä¸é”™ï¼Œè€Œä¸”æ—¶é—´ä¹Ÿæ˜¯æ¯”whisperæ›´å¿«çš„ï¼Œæ›´èƒ½è¾¾åˆ°å®æ—¶çš„æ•ˆæœï¼Œæ‰€ä»¥ä¹Ÿå°†FunASRæ·»åŠ è¿›å»äº†ï¼Œåœ¨ASRæ–‡ä»¶å¤¹ä¸‹çš„FunASRæ–‡ä»¶é‡Œå¯ä»¥è¿›è¡Œä½“éªŒï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ç¬¬ä¸€æ¬¡è¿è¡Œçš„æ—¶å€™ï¼Œéœ€è¦å®‰è£…ä»¥ä¸‹åº“ï¼Œå‚è€ƒ [https://github.com/alibaba-damo-academy/FunASR](https://github.com/alibaba-damo-academy/FunASR)

```bash
pip install funasr
pip install modelscope
pip install -U rotary_embedding_torch
```

```python
'''
Reference: https://github.com/alibaba-damo-academy/FunASR
pip install funasr
pip install modelscope
pip install -U rotary_embedding_torch
'''
try:
    from funasr import AutoModel
except:
    print("å¦‚æœæƒ³ä½¿ç”¨FunASRï¼Œè¯·å…ˆå®‰è£…funasrï¼Œè‹¥ä½¿ç”¨Whisperï¼Œè¯·å¿½ç•¥æ­¤æ¡ä¿¡æ¯")   

class FunASR:
    def __init__(self) -> None:
        self.model = AutoModel(model="paraformer-zh", model_revision="v2.0.4",
                vad_model="fsmn-vad", vad_model_revision="v2.0.4",
                punc_model="ct-punc-c", punc_model_revision="v2.0.4",
                # spk_model="cam++", spk_model_revision="v2.0.2",
                )

    def transcribe(self, audio_file):
        res = self.model.generate(input=audio_file, 
            batch_size_s=300)
        print(res)
        return res[0]['text']
```



## TTS - Edge TTS

ä½¿ç”¨å¾®è½¯è¯­éŸ³æœåŠ¡,å…·ä½“ä½¿ç”¨æ–¹æ³•å‚è€ƒ[https://github.com/rany2/edge-tts](https://github.com/rany2/edge-tts)

æˆ‘ç¼–å†™äº†ä¸€ä¸ª `EdgeTTS` çš„ç±»ï¼Œèƒ½å¤Ÿæ›´å¥½çš„ä½¿ç”¨ï¼Œå¹¶ä¸”å¢åŠ äº†ä¿å­˜å­—å¹•æ–‡ä»¶çš„åŠŸèƒ½

```python
class EdgeTTS:
    def __init__(self, list_voices = False, proxy = None) -> None:
        voices = list_voices_fn(proxy=proxy)
        self.SUPPORTED_VOICE = [item['ShortName'] for item in voices]
        self.SUPPORTED_VOICE.sort(reverse=True)
        if list_voices:
            print(", ".join(self.SUPPORTED_VOICE))

    def preprocess(self, rate, volume, pitch):
        if rate >= 0:
            rate = f'+{rate}%'
        else:
            rate = f'{rate}%'
        if pitch >= 0:
            pitch = f'+{pitch}Hz'
        else:
            pitch = f'{pitch}Hz'
        volume = 100 - volume
        volume = f'-{volume}%'
        return rate, volume, pitch

    def predict(self,TEXT, VOICE, RATE, VOLUME, PITCH, OUTPUT_FILE='result.wav', OUTPUT_SUBS='result.vtt', words_in_cue = 8):
        async def amain() -> None:
            """Main function"""
            rate, volume, pitch = self.preprocess(rate = RATE, volume = VOLUME, pitch = PITCH)
            communicate = Communicate(TEXT, VOICE, rate = rate, volume = volume, pitch = pitch)
            subs: SubMaker = SubMaker()
            sub_file: Union[TextIOWrapper, TextIO] = (
                open(OUTPUT_SUBS, "w", encoding="utf-8")
            )
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    # audio_file.write(chunk["data"])
                    pass
                elif chunk["type"] == "WordBoundary":
                    # print((chunk["offset"], chunk["duration"]), chunk["text"])
                    subs.create_sub((chunk["offset"], chunk["duration"]), chunk["text"])
            sub_file.write(subs.generate_subs(words_in_cue))
            await communicate.save(OUTPUT_FILE)
            
        
        # loop = asyncio.get_event_loop_policy().get_event_loop()
        # try:
        #     loop.run_until_complete(amain())
        # finally:
        #     loop.close()
        asyncio.run(amain())
        with open(OUTPUT_SUBS, 'r', encoding='utf-8') as file:
            vtt_lines = file.readlines()

        # å»æ‰æ¯ä¸€è¡Œæ–‡å­—ä¸­çš„ç©ºæ ¼
        vtt_lines_without_spaces = [line.replace(" ", "") if "-->" not in line else line for line in vtt_lines]
        # print(vtt_lines_without_spaces)
        with open(OUTPUT_SUBS, 'w', encoding='utf-8') as output_file:
            output_file.writelines(vtt_lines_without_spaces)
        return OUTPUT_FILE, OUTPUT_SUBS
```

åŒæ—¶åœ¨`src`æ–‡ä»¶å¤¹ä¸‹ï¼Œå†™äº†ä¸€ä¸ªç®€æ˜“çš„`WebUI`

```bash
python TTS_app.py
```

![TTS](docs/TTS.png)

## Voice Clone

### GPT-SoVITSï¼ˆæ¨èï¼‰

æ„Ÿè°¢å¤§å®¶çš„å¼€æºè´¡çŒ®ï¼Œæˆ‘å€Ÿé‰´äº†å½“å‰å¼€æºçš„è¯­éŸ³å…‹éš†æ¨¡å‹ `GPT-SoVITS`ï¼Œæˆ‘è®¤ä¸ºæ•ˆæœæ˜¯ç›¸å½“ä¸é”™çš„ï¼Œé¡¹ç›®åœ°å€å¯å‚è€ƒ[https://github.com/RVC-Boss/GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)

ä»–æœ‰ä»¥ä¸‹åŠŸèƒ½ï¼š

1. **é›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ï¼š** è¾“å…¥ 5 ç§’çš„å£°éŸ³æ ·æœ¬ï¼Œå³åˆ»ä½“éªŒæ–‡æœ¬åˆ°è¯­éŸ³è½¬æ¢ã€‚
2. **å°‘æ ·æœ¬ TTSï¼š** ä»…éœ€ 1 åˆ†é’Ÿçš„è®­ç»ƒæ•°æ®å³å¯å¾®è°ƒæ¨¡å‹ï¼Œæå‡å£°éŸ³ç›¸ä¼¼åº¦å’ŒçœŸå®æ„Ÿã€‚
3. **è·¨è¯­è¨€æ”¯æŒï¼š** æ”¯æŒä¸è®­ç»ƒæ•°æ®é›†ä¸åŒè¯­è¨€çš„æ¨ç†ï¼Œç›®å‰æ”¯æŒè‹±è¯­ã€æ—¥è¯­å’Œä¸­æ–‡ã€‚
4. **WebUI å·¥å…·ï¼š** é›†æˆå·¥å…·åŒ…æ‹¬å£°éŸ³ä¼´å¥åˆ†ç¦»ã€è‡ªåŠ¨è®­ç»ƒé›†åˆ†å‰²ã€ä¸­æ–‡è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)å’Œæ–‡æœ¬æ ‡æ³¨ï¼ŒååŠ©åˆå­¦è€…åˆ›å»ºè®­ç»ƒæ•°æ®é›†å’Œ GPT/SoVITS æ¨¡å‹ã€‚

ä¹‹å‰å¾ˆå¤šæ–¹æ³•éƒ½æ˜¯å°‘æ ·æœ¬ï¼Œæ¯”å¦‚`OpenVoice`å’Œ`XTTS`ï¼Œæˆ‘ä¹‹å‰ä¹Ÿæƒ³ç€ä½¿ç”¨ä»–ä»¬æ¥è¿›è¡Œå®ç°è¯­éŸ³å…‹éš†éƒ¨åˆ†ï¼Œä½†æ˜¯å¾ˆé—æ†¾çš„æ˜¯ï¼Œå¹¶æ²¡æœ‰æ„Ÿè§‰æœ‰å¾ˆå¥½çš„æ•ˆæœï¼Œå…¶å®`XTTS`è¿˜æ˜¯ä¸é”™çš„ï¼Œå¦‚æœæˆ‘ä»¬ç®€å•ç”¨éº¦å…‹é£ğŸ¤è¯´å‡ å¥è¯ä½œä¸ºå‚è€ƒæ¥è¿›è¡Œå…‹éš†ï¼Œæˆ‘è§‰å¾—æ•ˆæœè¿˜æ˜¯å¯ä»¥çš„ã€‚

ä½†æ˜¯å¦‚æœé‡åˆ°æ¯”è¾ƒé«˜çš„è¦æ±‚ï¼Œæˆ‘è§‰å¾—å¯èƒ½å°±éœ€è¦æ›´å¥½çš„æ¨¡å‹ï¼Œå¹¶ä¸”æˆæœ¬ä¹Ÿè¦æ‰“å‹ä¸‹æ¥ï¼Œæ‰€ä»¥æˆ‘å°±çœ‹åˆ°äº†è¿™ä¸ª`GPT-SoVITS`ï¼Œæˆ‘è§‰å¾—è¿™ä¸ªæ¨¡å‹æ˜¯ç›¸å½“å‰å®³çš„ï¼Œå°‘æ ·æœ¬çš„TTSèƒ½åšï¼Œä¹Ÿèƒ½åšè·¨è¯­è¨€æ”¯æŒï¼Œè¿™æ ·æˆ‘ä»¬å¾ˆæœ‰å¯èƒ½å°±å¯ä»¥ä½“éªŒåˆ°å¥¥å·´é©¬è®²ä¸­æ–‡ä¹‹ç±»çš„ï¼Œè¿™æ ·å°±å¯ä»¥å®Œæˆè§†é¢‘ç¿»è¯‘çš„ä¸€äº›ä»»åŠ¡äº†ï¼Œæ‰€ä»¥æˆ‘æ˜¯å¾ˆæ¨å´‡è¿™æ ·çš„ç®€å•å¾®è°ƒï¼Œæ•ˆæœåˆå¥½çš„æ–¹æ³•çš„ã€‚

ä¸ºäº†å°Šé‡ä½œè€…ï¼Œæˆ‘å¹¶æ²¡æœ‰æŠŠ`GPT-SoVITS`çš„å…¨å¥—ä»£ç æ¬è¿‡æ¥ï¼Œæˆ‘å†™äº†ä¸€ä¸ªå…³äºè¯­éŸ³å…‹éš†çš„ç±»ï¼Œå¤§å®¶å¯ä»¥å°†è®­ç»ƒå¥½çš„æ¨¡å‹å‚æ•°ä¸­ï¼Œå°±å¯ä»¥åœ¨æœ¬é¡¹ç›®ä½¿ç”¨ç»è¿‡è¯­éŸ³å…‹éš†åçš„TTSäº†ï¼Œå¸Œæœ›å¤§å®¶ç©çš„å¼€å¿ƒï¼Œç©çš„æ„‰å¿«ã€‚

> å¦‚æœä½¿ç”¨è¯­éŸ³å…‹éš†æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦pythonä¸º3.10ï¼Œpytorchä¸º2.1å·¦å³å¯èƒ½æ¯”è¾ƒå¥½ï¼Œæˆ‘çš„ç¯å¢ƒå·²ç»æµ‹è¯•è¿‡äº†ï¼Œç®€å•æ¥è¯´ï¼Œå…ˆå®‰è£…GPT-SoVITSçš„ç¯å¢ƒï¼Œå†ç›´æ¥pip intsall -r requirements_app.txtå³å¯ä½¿ç”¨

```python
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118
# å®‰è£…å¯¹åº”çš„ä¾èµ–
pip install -r VITS/requirements_gptsovits.txt

# å¯åŠ¨å¦‚ä¸‹çš„WebUIç•Œé¢
python VITS/app.py 
```

![](docs/GPT-SoVITS.png)

### XTTS

Coqui XTTSæ˜¯ä¸€ä¸ªé¢†å…ˆçš„æ·±åº¦å­¦ä¹ æ–‡æœ¬åˆ°è¯­éŸ³ä»»åŠ¡ï¼ˆTTSè¯­éŸ³ç”Ÿæˆæ¨¡å‹ï¼‰å·¥å…·åŒ…ï¼Œé€šè¿‡ä½¿ç”¨ä¸€æ®µ5ç§’é’Ÿä»¥ä¸Šçš„è¯­éŸ³é¢‘å‰ªè¾‘å°±å¯ä»¥å®Œæˆå£°éŸ³å…‹éš†*å°†è¯­éŸ³å…‹éš†åˆ°ä¸åŒçš„è¯­è¨€*ã€‚æ”¯æŒå¤šç§è¯­è¨€æ–‡æœ¬åˆ°è¯­éŸ³è½¬æ¢ï¼Œä½¿å…¶æˆä¸ºå›½é™…åŒ–åº”ç”¨çš„ç†æƒ³é€‰æ‹©ï¼Œè¿™ä¸€ç‰¹ç‚¹ç‰¹åˆ«é€‚ç”¨äºå…¨çƒåŒ–çš„å¸‚åœºï¼Œå…¶ä¸­éœ€è¦ç”Ÿæˆå¤šç§è¯­è¨€çš„è¯­éŸ³å†…å®¹ã€‚æ‰€ä»¥åœ¨å®éªŒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä¹ŸåŠ å…¥äº†è¿™ä¸€éƒ¨åˆ†ï¼Œä¸è¿‡æš‚æ—¶ä½¿ç”¨çš„æ˜¯é»˜è®¤çš„æ¨¡å‹ï¼Œå¹¶æ²¡æœ‰è¿›è¡Œå¾®è°ƒï¼Œä¸ªäººè®¤ä¸ºæ˜¯æ²¡æœ‰GPT-SoVITSç»è¿‡å¾®è°ƒåå¥½çš„ï¼Œä½†æ˜¯å…¶ä¸­çš„å°‘æ ·æœ¬äº”ç§’é’Ÿå…‹éš†è¯­éŸ³è¿˜æ˜¯å€¼å¾—ç§°èµçš„ã€‚å¤§å®¶ä¹Ÿå¯ä»¥åœ¨å®˜æ–¹çš„åœ¨çº¿ä½“éªŒï¼Œä½†æ˜¯å®˜æ–¹çš„å¯èƒ½ä¼šæœ‰ç”Ÿæˆè¯­éŸ³é™åˆ¶ï¼Œæ–‡å­—ä¸èƒ½å¤ªé•¿ï¼Œä½†æ˜¯è¿˜æ˜¯è¶³å¤Ÿæˆ‘ä»¬ä½“éªŒäº†ã€‚

ğŸ¸TTS æ˜¯ä¸€ä¸ªç”¨äºé«˜çº§æ–‡æœ¬è½¬è¯­éŸ³ç”Ÿæˆçš„åº“ã€‚

ğŸš€ è¶…è¿‡ 1100 ç§è¯­è¨€çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚

ğŸ› ï¸ ç”¨äºä»¥ä»»ä½•è¯­è¨€è®­ç»ƒæ–°æ¨¡å‹å’Œå¾®è°ƒç°æœ‰æ¨¡å‹çš„å·¥å…·ã€‚

ğŸ“š ç”¨äºæ•°æ®é›†åˆ†æå’Œç®¡ç†çš„å®ç”¨ç¨‹åºã€‚

- åœ¨çº¿ä½“éªŒXTTS [https://huggingface.co/spaces/coqui/xtts](https://huggingface.co/spaces/coqui/xtts)
- å®˜æ–¹Githubåº“ https://github.com/coqui-ai/TTS

XTTSçš„ç¯å¢ƒä¹Ÿéœ€è¦PyTorch 2.1æ‰€ä»¥ï¼Œå¦‚æœä¸‹è½½äº†GPT-SoVITSï¼Œä¹Ÿä¸å¦¨ä½“éªŒä¸€ä¸‹XTTSçš„æ•ˆæœã€‚

```bash
python VITS/XTTS.py
```

![](docs/XTTS.png)



## THG - Avatar

### SadTalker

æ•°å­—äººç”Ÿæˆå¯ä½¿ç”¨SadTalkerï¼ˆCVPR 2023ï¼‰,è¯¦æƒ…ä»‹ç»è§ [https://sadtalker.github.io](https://sadtalker.github.io)

åœ¨ä½¿ç”¨å‰å…ˆä¸‹è½½SadTalkeræ¨¡å‹:

```bash
bash scripts/sadtalker_download_models.sh  
```

[Baidu (ç™¾åº¦äº‘ç›˜)](https://pan.baidu.com/s/1eF13O-8wyw4B3MtesctQyg?pwd=linl) (Password: `linl`)

> å¦‚æœç™¾åº¦ç½‘ç›˜ä¸‹è½½ï¼Œè®°ä½æ˜¯æ”¾åœ¨checkpointsæ–‡ä»¶å¤¹ä¸‹ï¼Œç™¾åº¦ç½‘ç›˜ä¸‹è½½çš„é»˜è®¤å‘½åä¸ºsadtalkerï¼Œå®é™…åº”è¯¥é‡å‘½åä¸ºcheckpoints

### Wav2Lip

æ•°å­—äººç”Ÿæˆè¿˜å¯ä½¿ç”¨Wav2Lipï¼ˆACM 2020ï¼‰ï¼Œè¯¦æƒ…ä»‹ç»è§ [https://github.com/Rudrabha/Wav2Lip](https://github.com/Rudrabha/Wav2Lip)

åœ¨ä½¿ç”¨å‰å…ˆä¸‹è½½Wav2Lipæ¨¡å‹ï¼š

| Model                        | Description                                           | Link to the model                                            |
| ---------------------------- | ----------------------------------------------------- | ------------------------------------------------------------ |
| Wav2Lip                      | Highly accurate lip-sync                              | [Link](https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIY27JZg80f7V9jtMfbNDaQ?e=TBFBVW) |
| Wav2Lip + GAN                | Slightly inferior lip-sync, but better visual quality | [Link](https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA?e=n9ljGW) |
| Expert Discriminator         | Weights of the expert discriminator                   | [Link](https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EQRvmiZg-HRAjvI6zqN9eTEBP74KefynCwPWVmF57l-AYA?e=ZRPHKP) |
| Visual Quality Discriminator | Weights of the visual disc trained in a GAN setup     | [Link](https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EQVqH88dTm1HjlK11eNba5gBbn15WMS0B0EZbDBttqrqkg?e=ic0ljo) |

```python
class Wav2Lip:
    def __init__(self, path = 'checkpoints/wav2lip.pth'):
        self.fps = 25
        self.resize_factor = 1
        self.mel_step_size = 16
        self.static = False
        self.img_size = 96
        self.face_det_batch_size = 2
        self.box = [-1, -1, -1, -1]
        self.pads = [0, 10, 0, 0]
        self.nosmooth = False
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.model = self.load_model(path)

    def load_model(self, checkpoint_path):
        model = wav2lip_mdoel()
        print("Load checkpoint from: {}".format(checkpoint_path))
        if self.device == 'cuda':
            checkpoint = torch.load(checkpoint_path)
        else:
            checkpoint = torch.load(checkpoint_path,
                                    map_location=lambda storage, loc: storage)
        s = checkpoint["state_dict"]
        new_s = {}
        for k, v in s.items():
            new_s[k.replace('module.', '')] = v
        model.load_state_dict(new_s)

        model = model.to(self.device)
        return model.eval()
```



### ER-NeRFï¼ˆComming Soonï¼‰

ER-NeRFï¼ˆICCV2023ï¼‰æ˜¯ä½¿ç”¨æœ€æ–°çš„NeRFæŠ€æœ¯æ„å»ºçš„æ•°å­—äººï¼Œæ‹¥æœ‰å®šåˆ¶æ•°å­—äººçš„ç‰¹æ€§ï¼Œåªéœ€è¦ä¸€ä¸ªäººçš„äº”åˆ†é’Ÿå·¦å³åˆ°è§†é¢‘å³å¯é‡å»ºå‡ºæ¥ï¼Œå…·ä½“å¯å‚è€ƒ [https://github.com/Fictionarry/ER-NeRF](https://github.com/Fictionarry/ER-NeRF)

åç»­ä¼šé’ˆå¯¹æ­¤æ›´æ–°



## LLM - Conversation

### Linly-AI

Linlyæ¥è‡ªæ·±åœ³å¤§å­¦æ•°æ®å·¥ç¨‹å›½å®¶é‡ç‚¹å®éªŒå®¤,å‚è€ƒ[https://github.com/CVI-SZU/Linly](https://github.com/CVI-SZU/Linly)

ä¸‹è½½Linlyæ¨¡å‹:[https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf](https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf)

å¯ä»¥ä½¿ç”¨`git`ä¸‹è½½

```bash
git lfs install
git clone https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf
```

æˆ–è€…ä½¿ç”¨`huggingface`çš„ä¸‹è½½å·¥å…·`huggingface-cli`

```bash
pip install -U huggingface_hub

# è®¾ç½®é•œåƒåŠ é€Ÿ
# Linux
export HF_ENDPOINT="https://hf-mirror.com"
# windows powershell
$env:HF_ENDPOINT="https://hf-mirror.com"

huggingface-cli download --resume-download Linly-AI/Chinese-LLaMA-2-7B-hf --local-dir Linly-AI/Chinese-LLaMA-2-7B-hf
```

æˆ–ä½¿ç”¨API:

```bash
# å‘½ä»¤è¡Œ
curl -X POST -H "Content-Type: application/json" -d '{"question": "åŒ—äº¬æœ‰ä»€ä¹ˆå¥½ç©çš„åœ°æ–¹?"}' http://url:port

# Python
import requests

url = "http://url:port"
headers = {
  "Content-Type": "application/json"
}

data = {
  "question": "åŒ—äº¬æœ‰ä»€ä¹ˆå¥½ç©çš„åœ°æ–¹?" 
}

response = requests.post(url, headers=headers, json=data)
# response_text = response.content.decode("utf-8")
answer, tag = response.json()
# print(answer)
if tag == 'success':
    response_text =  answer[0]
else:
    print("fail")
print(response_text)
```

APIéƒ¨ç½²æ¨è**FastAPI**ï¼Œç°åœ¨æ›´æ–°äº† FastAPI çš„APIä½¿ç”¨ç‰ˆæœ¬ï¼ŒFastAPI æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ã€æ˜“ç”¨ä¸”ç°ä»£çš„Python Web æ¡†æ¶ï¼Œå®ƒé€šè¿‡ä½¿ç”¨æœ€æ–°çš„Python ç‰¹æ€§å’Œå¼‚æ­¥ç¼–ç¨‹ï¼Œæä¾›äº†å¿«é€Ÿå¼€å‘Web API çš„èƒ½åŠ›ã€‚ è¯¥æ¡†æ¶ä¸ä»…æ˜“äºå­¦ä¹ å’Œä½¿ç”¨ï¼Œè¿˜å…·æœ‰è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£ã€æ•°æ®éªŒè¯ç­‰å¼ºå¤§åŠŸèƒ½ã€‚ æ— è®ºæ˜¯æ„å»ºå°å‹é¡¹ç›®è¿˜æ˜¯å¤§å‹åº”ç”¨ç¨‹åºï¼ŒFastAPI éƒ½æ˜¯ä¸€ä¸ªå¼ºå¤§è€Œæœ‰æ•ˆçš„å·¥å…·ã€‚

é¦–å…ˆå®‰è£…éƒ¨ç½²APIæ‰€ä½¿ç”¨çš„åº“

```bash
pip install fastapi==0.104.1
pip install uvicorn==0.24.0.post1
```

å…¶ä»–ä½¿ç”¨æ–¹æ³•å¤§è‡´ç›¸åŒï¼Œä¸»è¦æ˜¯ä¸åŒä»£ç å®ç°æ–¹å¼ï¼Œä¼šæ›´åŠ ç®€å•è¾¹ç•Œï¼Œå¹¶ä¸”å¤„ç†å¹¶å‘ä¹Ÿä¼šæ›´å¥½

```python
from fastapi import FastAPI, Request
from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig
import uvicorn
import json
import datetime
import torch
from configs import model_path, api_port
# è®¾ç½®è®¾å¤‡å‚æ•°
DEVICE = "cuda"  # ä½¿ç”¨CUDA
DEVICE_ID = "0"  # CUDAè®¾å¤‡IDï¼Œå¦‚æœæœªè®¾ç½®åˆ™ä¸ºç©º
CUDA_DEVICE = f"{DEVICE}:{DEVICE_ID}" if DEVICE_ID else DEVICE  # ç»„åˆCUDAè®¾å¤‡ä¿¡æ¯

# æ¸…ç†GPUå†…å­˜å‡½æ•°
def torch_gc():
    if torch.cuda.is_available():  # æ£€æŸ¥æ˜¯å¦å¯ç”¨CUDA
        with torch.cuda.device(CUDA_DEVICE):  # æŒ‡å®šCUDAè®¾å¤‡
            torch.cuda.empty_cache()  # æ¸…ç©ºCUDAç¼“å­˜
            torch.cuda.ipc_collect()  # æ”¶é›†CUDAå†…å­˜ç¢ç‰‡

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI()

# å¤„ç†POSTè¯·æ±‚çš„ç«¯ç‚¹
@app.post("/")
async def create_item(request: Request):
    global model, tokenizer  # å£°æ˜å…¨å±€å˜é‡ä»¥ä¾¿åœ¨å‡½æ•°å†…éƒ¨ä½¿ç”¨æ¨¡å‹å’Œåˆ†è¯å™¨
    json_post_raw = await request.json()  # è·å–POSTè¯·æ±‚çš„JSONæ•°æ®
    json_post = json.dumps(json_post_raw)  # å°†JSONæ•°æ®è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    json_post_list = json.loads(json_post)  # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºPythonå¯¹è±¡
    prompt = json_post_list.get('prompt')  # è·å–è¯·æ±‚ä¸­çš„æç¤º
    history = json_post_list.get('history')  # è·å–è¯·æ±‚ä¸­çš„å†å²è®°å½•
    max_length = json_post_list.get('max_length')  # è·å–è¯·æ±‚ä¸­çš„æœ€å¤§é•¿åº¦
    top_p = json_post_list.get('top_p')  # è·å–è¯·æ±‚ä¸­çš„top_på‚æ•°
    temperature = json_post_list.get('temperature')  # è·å–è¯·æ±‚ä¸­çš„æ¸©åº¦å‚æ•°
    
    # è°ƒç”¨æ¨¡å‹è¿›è¡Œå¯¹è¯ç”Ÿæˆ
    prompt = f"è¯·ç”¨å°‘äº25ä¸ªå­—å›ç­”ä»¥ä¸‹é—®é¢˜ ### Instruction:{prompt}  ### Response:"
    inputs = tokenizer(prompt, return_tensors="pt").to("cuda:0")
    generate_ids = model.generate(inputs.input_ids, 
                                  max_new_tokens=max_length if max_length else 2048,
                                  do_sample=True, 
                                  top_k=20,
                                  top_p=top_p,
                                  temperature=temperature if temperature else 0.84,
                                  repetition_penalty=1.15, eos_token_id=2, bos_token_id=1,pad_token_id=0)
    response = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]
    response = response.split("### Response:")[-1]
    now = datetime.datetime.now()  # è·å–å½“å‰æ—¶é—´
    time = now.strftime("%Y-%m-%d %H:%M:%S")  # æ ¼å¼åŒ–æ—¶é—´ä¸ºå­—ç¬¦ä¸²
    # æ„å»ºå“åº”JSON
    answer = {
        "response": response,
        # "history": history,
        "status": 200,
        "time": time
    }
    # æ„å»ºæ—¥å¿—ä¿¡æ¯
    log = "[" + time + "] " + '", prompt:"' + prompt + '", response:"' + repr(response) + '"'
    print(log)  # æ‰“å°æ—¥å¿—
    torch_gc()  # æ‰§è¡ŒGPUå†…å­˜æ¸…ç†
    return answer  # è¿”å›å“åº”

# ä¸»å‡½æ•°å…¥å£
if __name__ == '__main__':
    # åŠ è½½é¢„è®­ç»ƒçš„åˆ†è¯å™¨å’Œæ¨¡å‹
    model = AutoModelForCausalLM.from_pretrained(model_path, device_map="cuda:0",
                                                    torch_dtype=torch.bfloat16, trust_remote_code=True)
    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False, trust_remote_code=True)
    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    # å¯åŠ¨FastAPIåº”ç”¨
    uvicorn.run(app, host='0.0.0.0', port=api_port, workers=1)  # åœ¨æŒ‡å®šç«¯å£å’Œä¸»æœºä¸Šå¯åŠ¨åº”ç”¨
```

é»˜è®¤éƒ¨ç½²åœ¨ 7871 ç«¯å£ï¼Œé€šè¿‡ POST æ–¹æ³•è¿›è¡Œè°ƒç”¨ï¼Œå¯ä»¥ä½¿ç”¨curlè°ƒç”¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
curl -X POST "http://127.0.0.1:7871" \
     -H 'Content-Type: application/json' \
     -d '{"prompt": "å¦‚ä½•åº”å¯¹å‹åŠ›"}'
```

ä¹Ÿå¯ä»¥ä½¿ç”¨pythonä¸­çš„requestsåº“è¿›è¡Œè°ƒç”¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```python
import requests
import json

def get_completion(prompt):
    headers = {'Content-Type': 'application/json'}
    data = {"prompt": prompt}
    response = requests.post(url='http://127.0.0.1:7871', headers=headers, data=json.dumps(data))
    return response.json()['response']

if __name__ == '__main__':
    print(get_completion('ä½ å¥½å¦‚ä½•åº”å¯¹å‹åŠ›'))
```

å¾—åˆ°çš„è¿”å›å€¼å¦‚ä¸‹æ‰€ç¤ºï¼š

```bash
{
  "response":"å¯»æ±‚æ”¯æŒå’Œæ”¾æ¾ï¼Œå¹¶é‡‡å–ç§¯æçš„æªæ–½è§£å†³é—®é¢˜ã€‚",
  "status":200,
  "time":"2024-01-12 01:43:37"
}
```



### Qwen

æ¥è‡ªé˜¿é‡Œäº‘çš„Qwenï¼ŒæŸ¥çœ‹ [https://github.com/QwenLM/Qwen](https://github.com/QwenLM/Qwen)

å¦‚æœæƒ³è¦å¿«é€Ÿä½¿ç”¨ï¼Œå¯ä»¥é€‰1.8Bçš„æ¨¡å‹ï¼Œå‚æ•°æ¯”è¾ƒå°‘ï¼Œåœ¨è¾ƒå°çš„æ˜¾å­˜ä¹Ÿå¯ä»¥æ­£å¸¸ä½¿ç”¨ï¼Œå½“ç„¶è¿™ä¸€éƒ¨åˆ†å¯ä»¥æ›¿æ¢

ä¸‹è½½ Qwen1.8B æ¨¡å‹: [https://huggingface.co/Qwen/Qwen-1_8B-Chat](https://huggingface.co/Qwen/Qwen-1_8B-Chat)

å¯ä»¥ä½¿ç”¨`git`ä¸‹è½½

```bash
git lfs install
git clone https://huggingface.co/Qwen/Qwen-1_8B-Chat
```

æˆ–è€…ä½¿ç”¨`huggingface`çš„ä¸‹è½½å·¥å…·`huggingface-cli`

```bash
pip install -U huggingface_hub

# è®¾ç½®é•œåƒåŠ é€Ÿ
# Linux
export HF_ENDPOINT="https://hf-mirror.com"
# windows powershell
$env:HF_ENDPOINT="https://hf-mirror.com"

huggingface-cli download --resume-download Qwen/Qwen-1_8B-Chat --local-dir Qwen/Qwen-1_8B-Chat
```

å¦‚æœå‡ºç°äº†ä¸€äº›ç½‘ç»œé—®é¢˜ï¼Œå¤§å®¶å…¶å®å¯ä»¥ç”¨é­”æ­ç¤¾åŒºè¿›è¡Œä¸‹è½½ï¼Œé€Ÿåº¦å¾ˆå¿«ï¼Œæœ€åä¿®æ”¹è·¯å¾„å³å¯ [https://modelscope.cn/models/qwen/Qwen-1_8B-Chat/files](https://modelscope.cn/models/qwen/Qwen-1_8B-Chat/files)

```python
# æ¨¡å‹ä¸‹è½½
from modelscope import snapshot_download
model_dir = snapshot_download('qwen/Qwen-1_8B-Chat')
```

### Gemini-Pro

æ¥è‡ª Google çš„ Gemini-Proï¼Œäº†è§£æ›´å¤šè¯·è®¿é—® [https://deepmind.google/technologies/gemini/](https://deepmind.google/technologies/gemini/)

è¯·æ±‚ API å¯†é’¥: [https://makersuite.google.com/](https://makersuite.google.com/)



### LLM æ¨¡å‹é€‰æ‹©

åœ¨ app.py æ–‡ä»¶ä¸­ï¼Œè½»æ¾é€‰æ‹©æ‚¨éœ€è¦çš„æ¨¡å‹ã€‚

```python
# å¯ä»¥æ³¨é‡Šæ‰é€‰æ‹©æ¨¡å‹
# llm = LLM(mode='offline').init_model('Linly', 'Linly-AI/Chinese-LLaMA-2-7B-hf')
# llm = LLM(mode='offline').init_model('Gemini', 'gemini-pro', api_key = "your api key")
# llm = LLM(mode='offline').init_model('Qwen', 'Qwen/Qwen-1_8B-Chat')

# å¯ä»¥é€šè¿‡configæ¥è®¾ç½®æ¨¡å‹
llm = LLM(mode=mode).init_model('Qwen', model_path)
```



## ä¼˜åŒ–

ä¸€äº›ä¼˜åŒ–:

- ä½¿ç”¨å›ºå®šçš„è¾“å…¥äººè„¸å›¾åƒ,æå‰æå–ç‰¹å¾,é¿å…æ¯æ¬¡è¯»å–
- ç§»é™¤ä¸å¿…è¦çš„åº“,ç¼©çŸ­æ€»æ—¶é—´
- åªä¿å­˜æœ€ç»ˆè§†é¢‘è¾“å‡º,ä¸ä¿å­˜ä¸­é—´ç»“æœ,æé«˜æ€§èƒ½
- ä½¿ç”¨OpenCVç”Ÿæˆæœ€ç»ˆè§†é¢‘,æ¯”mimwriteæ›´å¿«

## Gradio

Gradioæ˜¯ä¸€ä¸ªPythonåº“,æä¾›äº†ä¸€ç§ç®€å•çš„æ–¹å¼å°†æœºå™¨å­¦ä¹ æ¨¡å‹ä½œä¸ºäº¤äº’å¼Webåº”ç”¨ç¨‹åºæ¥éƒ¨ç½²ã€‚

å¯¹Linly-Talkerè€Œè¨€,ä½¿ç”¨Gradioæœ‰ä¸¤ä¸ªä¸»è¦ç›®çš„:

1. **å¯è§†åŒ–ä¸æ¼”ç¤º**:Gradioä¸ºæ¨¡å‹æä¾›ä¸€ä¸ªç®€å•çš„Web GUI,ä¸Šä¼ å›¾ç‰‡å’Œæ–‡æœ¬åå¯ä»¥ç›´è§‚åœ°çœ‹åˆ°ç»“æœã€‚è¿™æ˜¯å±•ç¤ºç³»ç»Ÿèƒ½åŠ›çš„æœ‰æ•ˆæ–¹å¼ã€‚

2. **ç”¨æˆ·äº¤äº’**:Gradioçš„GUIå¯ä»¥ä½œä¸ºå‰ç«¯,å…è®¸ç”¨æˆ·ä¸Linly-Talkerè¿›è¡Œäº¤äº’å¯¹è¯ã€‚ç”¨æˆ·å¯ä»¥ä¸Šä¼ è‡ªå·±çš„å›¾ç‰‡å¹¶è¾“å…¥é—®é¢˜,å®æ—¶è·å–å›ç­”ã€‚è¿™æä¾›äº†æ›´è‡ªç„¶çš„è¯­éŸ³äº¤äº’æ–¹å¼ã€‚

å…·ä½“æ¥è¯´,æˆ‘ä»¬åœ¨app.pyä¸­åˆ›å»ºäº†ä¸€ä¸ªGradioçš„Interface,æ¥æ”¶å›¾ç‰‡å’Œæ–‡æœ¬è¾“å…¥,è°ƒç”¨å‡½æ•°ç”Ÿæˆå›åº”è§†é¢‘,åœ¨GUIä¸­æ˜¾ç¤ºå‡ºæ¥ã€‚è¿™æ ·å°±å®ç°äº†æµè§ˆå™¨äº¤äº’è€Œä¸éœ€è¦ç¼–å†™å¤æ‚çš„å‰ç«¯ã€‚

æ€»ä¹‹,Gradioä¸ºLinly-Talkeræä¾›äº†å¯è§†åŒ–å’Œç”¨æˆ·äº¤äº’çš„æ¥å£,æ˜¯å±•ç¤ºç³»ç»ŸåŠŸèƒ½å’Œè®©æœ€ç»ˆç”¨æˆ·ä½¿ç”¨ç³»ç»Ÿçš„æœ‰æ•ˆé€”å¾„ã€‚

## å¯åŠ¨WebUI

ä¹‹å‰æˆ‘å°†å¾ˆå¤šä¸ªç‰ˆæœ¬éƒ½æ˜¯åˆ†å¼€æ¥çš„ï¼Œå®é™…ä¸Šè¿è¡Œå¤šä¸ªä¼šæ¯”è¾ƒéº»çƒ¦ï¼Œæ‰€ä»¥åç»­æˆ‘å¢åŠ äº†å˜æˆWebUIä¸€ä¸ªç•Œé¢å³å¯ä½“éªŒï¼Œåç»­ä¹Ÿä¼šä¸æ–­æ›´æ–°

ç°åœ¨å·²åŠ å…¥WebUIçš„åŠŸèƒ½å¦‚ä¸‹

- [x] æ–‡æœ¬/è¯­éŸ³æ•°å­—äººå¯¹è¯ï¼ˆå›ºå®šæ•°å­—äººï¼Œåˆ†ç”·å¥³è§’è‰²ï¼‰
- [x] ä»»æ„å›¾ç‰‡æ•°å­—äººå¯¹è¯ï¼ˆå¯ä¸Šä¼ ä»»æ„æ•°å­—äººï¼‰
- [x] å¤šè½®GPTå¯¹è¯ï¼ˆåŠ å…¥å†å²å¯¹è¯æ•°æ®ï¼Œé“¾æ¥ä¸Šä¸‹æ–‡ï¼‰
- [x] è¯­éŸ³å…‹éš†å¯¹è¯ï¼ˆåŸºäºGPT-SoVITSè®¾ç½®è¿›è¡Œè¯­éŸ³å…‹éš†ï¼Œå†…ç½®çƒŸå—“éŸ³ï¼Œå¯æ ¹æ®è¯­éŸ³å¯¹è¯çš„å£°éŸ³è¿›è¡Œå…‹éš†ï¼‰

```bash
# WebUI
python webui.py
```

![](docs/WebUI.png)



ç°åœ¨çš„å¯åŠ¨ä¸€å…±æœ‰å‡ ç§æ¨¡å¼ï¼Œå¯ä»¥é€‰æ‹©ç‰¹å®šçš„åœºæ™¯è¿›è¡Œè®¾ç½®

ç¬¬ä¸€ç§åªæœ‰å›ºå®šäº†äººç‰©é—®ç­”ï¼Œè®¾ç½®å¥½äº†äººç‰©ï¼Œçœå»äº†é¢„å¤„ç†æ—¶é—´

```bash
python app.py
```

![](docs/UI.png)

æœ€è¿‘æ›´æ–°äº†ç¬¬ä¸€ç§æ¨¡å¼ï¼ŒåŠ å…¥äº†Wav2Lipæ¨¡å‹è¿›è¡Œå¯¹è¯

```bash
python appv2.py
```

ç¬¬äºŒç§æ˜¯å¯ä»¥ä»»æ„ä¸Šä¼ å›¾ç‰‡è¿›è¡Œå¯¹è¯

```bash
python app_img.py
```

![](docs/UI2.png)

ç¬¬ä¸‰ç§æ˜¯åœ¨ç¬¬ä¸€ç§çš„åŸºç¡€ä¸ŠåŠ å…¥äº†å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŠ å…¥äº†å¤šè½®çš„GPTå¯¹è¯

```bash
python app_multi.py
```

![](docs/UI3.png)

ç°åœ¨åŠ å…¥äº†è¯­éŸ³å…‹éš†çš„éƒ¨åˆ†ï¼Œå¯ä»¥è‡ªç”±åˆ‡æ¢è‡ªå·±å…‹éš†çš„å£°éŸ³æ¨¡å‹å’Œå¯¹åº”çš„äººå›¾ç‰‡è¿›è¡Œå®ç°ï¼Œè¿™é‡Œæˆ‘é€‰æ‹©äº†ä¸€ä¸ªçƒŸå—“éŸ³å’Œç”·ç”Ÿå›¾ç‰‡

```bash
python app_vits.py
```

æ–‡ä»¶å¤¹ç»“æ„å¦‚ä¸‹

æƒé‡éƒ¨åˆ†å¯ä»¥ä»è¿™ä¸‹è½½ï¼š[Baidu (ç™¾åº¦äº‘ç›˜)](https://pan.baidu.com/s/1eF13O-8wyw4B3MtesctQyg?pwd=linl) (Password: `linl`)

```bash
Linly-Talker/ 
â”œâ”€â”€ app.py
â”œâ”€â”€ app_img.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ Linly-api.py
â”œâ”€â”€ Linly-api-fast.py
â”œâ”€â”€ Linly-example.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ README_zh.md
â”œâ”€â”€ request-Linly-api.py
â”œâ”€â”€ requirements_app.txt
â”œâ”€â”€ scripts
â”‚   â””â”€â”€ download_models.sh
â”œâ”€â”€	src
â”‚Â Â  â”œâ”€â”€ audio2exp_models
â”‚Â Â  â”œâ”€â”€ audio2pose_models
â”‚Â Â  â”œâ”€â”€ config
â”‚Â Â  â”œâ”€â”€ cost_time.py
â”‚Â Â  â”œâ”€â”€ face3d
â”‚Â Â  â”œâ”€â”€ facerender
â”‚Â Â  â”œâ”€â”€ generate_batch.py
â”‚Â Â  â”œâ”€â”€ generate_facerender_batch.py
â”‚Â Â  â”œâ”€â”€ Record.py
â”‚Â Â  â”œâ”€â”€ test_audio2coeff.py
â”‚Â Â  â””â”€â”€ utils
â”œâ”€â”€ inputs
â”‚   â”œâ”€â”€ example.png
â”‚   â””â”€â”€ first_frame_dir
â”‚       â”œâ”€â”€ example_landmarks.txt
â”‚       â”œâ”€â”€ example.mat
â”‚       â””â”€â”€ example.png
â”œâ”€â”€ examples
â”‚   â””â”€â”€ source_image
â”‚       â”œâ”€â”€ art_0.png
â”‚       â”œâ”€â”€ ......
â”‚       â””â”€â”€ sad.png
â”œâ”€â”€ TFG
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â   â”œâ”€â”€ Wav2Lip.py
â”‚Â Â  â””â”€â”€ SadTalker.py
â””â”€â”€ TTS
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â   â”œâ”€â”€ EdgeTTS.py
â”‚Â   â””â”€â”€ TTS_app.py
â”œâ”€â”€ ASR
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ FunASR.py
â”‚Â Â  â””â”€â”€ Whisper.py
â”œâ”€â”€ LLM
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ Gemini.py
â”‚Â Â  â”œâ”€â”€ Linly.py
â”‚Â Â  â””â”€â”€ Qwen.py
....... // ä»¥ä¸‹æ˜¯éœ€è¦ä¸‹è½½çš„æƒé‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ checkpoints // SadTalker æƒé‡è·¯å¾„
â”‚   â”œâ”€â”€ mapping_00109-model.pth.tar
â”‚   â”œâ”€â”€ mapping_00229-model.pth.tar
â”‚   â”œâ”€â”€ SadTalker_V0.0.2_256.safetensors
â”‚   â””â”€â”€ SadTalker_V0.0.2_512.safetensors
â”‚   â”œâ”€â”€ lipsync_expert.pth
â”‚   â”œâ”€â”€ visual_quality_disc.pth
â”‚   â”œâ”€â”€ wav2lip_gan.pth
â”‚   â””â”€â”€ wav2lip.pth // Wav2Lip æƒé‡é™†å†›
â”œâ”€â”€ gfpgan // GFPGAN æƒé‡è·¯å¾„
â”‚   â””â”€â”€ weights
â”‚       â”œâ”€â”€ alignment_WFLW_4HG.pth
â”‚       â””â”€â”€ detection_Resnet50_Final.pth
â”œâ”€â”€ Linly-AI // Linly æƒé‡è·¯å¾„
â”‚   â””â”€â”€ Chinese-LLaMA-2-7B-hf 
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ generation_config.json
â”‚       â”œâ”€â”€ pytorch_model-00001-of-00002.bin
â”‚       â”œâ”€â”€ pytorch_model-00002-of-00002.bin
â”‚       â”œâ”€â”€ pytorch_model.bin.index.json
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ special_tokens_map.json
â”‚       â”œâ”€â”€ tokenizer_config.json
â”‚       â””â”€â”€ tokenizer.model
â”œâ”€â”€ Qwen // Qwen æƒé‡è·¯å¾„
â”‚   â””â”€â”€ Qwen-1_8B-Chat
â”‚       â”œâ”€â”€ cache_autogptq_cuda_256.cpp
â”‚       â”œâ”€â”€ cache_autogptq_cuda_kernel_256.cu
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ configuration_qwen.py
â”‚       â”œâ”€â”€ cpp_kernels.py
â”‚       â”œâ”€â”€ examples
â”‚       â”‚   â””â”€â”€ react_prompt.md
â”‚       â”œâ”€â”€ generation_config.json
â”‚       â”œâ”€â”€ LICENSE
â”‚       â”œâ”€â”€ model-00001-of-00002.safetensors
â”‚       â”œâ”€â”€ model-00002-of-00002.safetensors
â”‚       â”œâ”€â”€ modeling_qwen.py
â”‚       â”œâ”€â”€ model.safetensors.index.json
â”‚       â”œâ”€â”€ NOTICE
â”‚       â”œâ”€â”€ qwen_generation_utils.py
â”‚       â”œâ”€â”€ qwen.tiktoken
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ tokenization_qwen.py
â”‚       â””â”€â”€ tokenizer_config.json
```



## å‚è€ƒ

- [https://github.com/openai/whisper](https://github.com/openai/whisper)
- [https://github.com/rany2/edge-tts](https://github.com/rany2/edge-tts)  
- [https://github.com/CVI-SZU/Linly](https://github.com/CVI-SZU/Linly)
- [https://github.com/QwenLM/Qwen](https://github.com/QwenLM/Qwen)
- [https://deepmind.google/technologies/gemini/](https://deepmind.google/technologies/gemini/)
- [https://github.com/OpenTalker/SadTalker](https://github.com/OpenTalker/SadTalker)
- [https://github.com/RVC-Boss/GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Kedreamix/Linly-Talker&type=Date)](https://star-history.com/#Kedreamix/Linly-Talker&Date)

