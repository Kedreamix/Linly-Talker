# æ•°å­—äººå¯¹è¯ç³»ç»Ÿ Linly-Talker

[English](./README.md) [ç®€ä½“ä¸­æ–‡](./README_zh.md)

**2023.12 æ›´æ–°** ğŸ“†

**ç”¨æˆ·å¯ä»¥ä¸Šä¼ ä»»æ„å›¾ç‰‡è¿›è¡Œå¯¹è¯**

## ä»‹ç»

Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚

![The system architecture of multimodal humanâ€“computer interaction.](HOI.png)

## åˆ›å»ºç¯å¢ƒ

```
conda create -n linly python=3.8 
conda activate linly

pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113

conda install ffmpeg 

pip install -r requirements_app.txt
```

## ASR - Whisper

å€Ÿé‰´OpenAIçš„Whisper,å…·ä½“ä½¿ç”¨æ–¹æ³•å‚è€ƒ[https://github.com/openai/whisper](https://github.com/openai/whisper)

## TTS - Edge TTS

ä½¿ç”¨å¾®è½¯è¯­éŸ³æœåŠ¡,å…·ä½“ä½¿ç”¨æ–¹æ³•å‚è€ƒ[https://github.com/rany2/edge-tts](https://github.com/rany2/edge-tts)

## THG - SadTalker

è¯´è¯å¤´ç”Ÿæˆä½¿ç”¨SadTalker,å‚è€ƒCVPR 2023,è¯¦æƒ…è§[https://sadtalker.github.io](https://sadtalker.github.io)

ä¸‹è½½SadTalkeræ¨¡å‹:

```
bash scripts/download_models.sh  
```

## LLM - Linly

Linlyæ¥è‡ªæ·±åœ³å¤§å­¦æ•°æ®å·¥ç¨‹å›½å®¶é‡ç‚¹å®éªŒå®¤,å‚è€ƒhttps://github.com/CVI-SZU/Linly

ä¸‹è½½Linlyæ¨¡å‹:https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf

```
git lfs install
git clone https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf
```

æˆ–ä½¿ç”¨API:

```
# å‘½ä»¤è¡Œ
curl -X POST -H "Content-Type: application/json" -d '{"question": "åŒ—äº¬æœ‰ä»€ä¹ˆå¥½ç©çš„åœ°æ–¹?"}' http://url:port  

# Python
import requests

url = "http://url:port"
headers = {
  "Content-Type": "application/json"
}

data = {
  "question": "åŒ—äº¬æœ‰ä»€ä¹ˆå¥½ç©çš„åœ°æ–¹?" 
}

response = requests.post(url, headers=headers, json=data)
# response_text = response.content.decode("utf-8")
answer, tag = response.json()
# print(answer)
if tag == 'success':
    response_text =  answer[0]
else:
    print("fail")
print(response_text)
```

## ä¼˜åŒ–

ä¸€äº›ä¼˜åŒ–:

- ä½¿ç”¨å›ºå®šçš„è¾“å…¥äººè„¸å›¾åƒ,æå‰æå–ç‰¹å¾,é¿å…æ¯æ¬¡è¯»å–
- ç§»é™¤ä¸å¿…è¦çš„åº“,ç¼©çŸ­æ€»æ—¶é—´
- åªä¿å­˜æœ€ç»ˆè§†é¢‘è¾“å‡º,ä¸ä¿å­˜ä¸­é—´ç»“æœ,æé«˜æ€§èƒ½
- ä½¿ç”¨OpenCVç”Ÿæˆæœ€ç»ˆè§†é¢‘,æ¯”mimwriteæ›´å¿«

## Gradio

Gradioæ˜¯ä¸€ä¸ªPythonåº“,æä¾›äº†ä¸€ç§ç®€å•çš„æ–¹å¼å°†æœºå™¨å­¦ä¹ æ¨¡å‹ä½œä¸ºäº¤äº’å¼Webåº”ç”¨ç¨‹åºæ¥éƒ¨ç½²ã€‚

å¯¹Linly-Talkerè€Œè¨€,ä½¿ç”¨Gradioæœ‰ä¸¤ä¸ªä¸»è¦ç›®çš„:

1. **å¯è§†åŒ–ä¸æ¼”ç¤º**:Gradioä¸ºæ¨¡å‹æä¾›ä¸€ä¸ªç®€å•çš„Web GUI,ä¸Šä¼ å›¾ç‰‡å’Œæ–‡æœ¬åå¯ä»¥ç›´è§‚åœ°çœ‹åˆ°ç»“æœã€‚è¿™æ˜¯å±•ç¤ºç³»ç»Ÿèƒ½åŠ›çš„æœ‰æ•ˆæ–¹å¼ã€‚

2. **ç”¨æˆ·äº¤äº’**:Gradioçš„GUIå¯ä»¥ä½œä¸ºå‰ç«¯,å…è®¸ç”¨æˆ·ä¸Linly-Talkerè¿›è¡Œäº¤äº’å¯¹è¯ã€‚ç”¨æˆ·å¯ä»¥ä¸Šä¼ è‡ªå·±çš„å›¾ç‰‡å¹¶è¾“å…¥é—®é¢˜,å®æ—¶è·å–å›ç­”ã€‚è¿™æä¾›äº†æ›´è‡ªç„¶çš„è¯­éŸ³äº¤äº’æ–¹å¼ã€‚

å…·ä½“æ¥è¯´,æˆ‘ä»¬åœ¨app.pyä¸­åˆ›å»ºäº†ä¸€ä¸ªGradioçš„Interface,æ¥æ”¶å›¾ç‰‡å’Œæ–‡æœ¬è¾“å…¥,è°ƒç”¨å‡½æ•°ç”Ÿæˆå›åº”è§†é¢‘,åœ¨GUIä¸­æ˜¾ç¤ºå‡ºæ¥ã€‚è¿™æ ·å°±å®ç°äº†æµè§ˆå™¨äº¤äº’è€Œä¸éœ€è¦ç¼–å†™å¤æ‚çš„å‰ç«¯ã€‚

æ€»ä¹‹,Gradioä¸ºLinly-Talkeræä¾›äº†å¯è§†åŒ–å’Œç”¨æˆ·äº¤äº’çš„æ¥å£,æ˜¯å±•ç¤ºç³»ç»ŸåŠŸèƒ½å’Œè®©æœ€ç»ˆç”¨æˆ·ä½¿ç”¨ç³»ç»Ÿçš„æœ‰æ•ˆé€”å¾„ã€‚

## å¯åŠ¨

```
python app.py
```

![](UI.jpg)

å¯ä»¥ä»»æ„ä¸Šä¼ å›¾ç‰‡è¿›è¡Œå¯¹è¯

```bash
python app_img.py
```

![](UI2.jpg)



## å‚è€ƒ

- [https://github.com/openai/whisper](https://github.com/openai/whisper)
- [https://github.com/rany2/edge-tts](https://github.com/rany2/edge-tts)  
- [https://github.com/CVI-SZU/Linly](https://github.com/CVI-SZU/Linly)
- [https://github.com/OpenTalker/SadTalker](https://github.com/OpenTalker/SadTalker)

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Kedreamix/Linly-Talker&type=Date)](https://star-history.com/#Kedreamix/Linly-Talker&Date)

